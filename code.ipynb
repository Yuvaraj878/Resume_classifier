{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b4f31b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9948186528497409\n",
      "Prediction: ETL Developer | Actual: ETL Developer\n",
      "Prediction: Health and fitness | Actual: Health and fitness\n",
      "Prediction: Advocate | Actual: Advocate\n",
      "Prediction: Automation Testing | Actual: Automation Testing\n",
      "Prediction: Operations Manager | Actual: Operations Manager\n",
      "Prediction: PMO | Actual: PMO\n",
      "Prediction: Java Developer | Actual: Java Developer\n",
      "Prediction: Civil Engineer | Actual: Civil Engineer\n",
      "Prediction: Operations Manager | Actual: Operations Manager\n",
      "Prediction: Operations Manager | Actual: Operations Manager\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Import libraries\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load spaCy model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# STEP 2: Upload DataSet\n",
    "df = pd.read_csv('UpdatedResumeDataSet.csv')\n",
    "\n",
    "# Use only relevant columns\n",
    "df = df[['Resume', 'Category']].dropna()\n",
    "\n",
    "# STEP 3: Preprocess resume text using spaCy\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "    tokens = [token.lemma_.lower() for token in doc if token.is_alpha and not token.is_stop]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df['cleaned_resume'] = df['Resume'].apply(preprocess)\n",
    "\n",
    "# STEP 4: TF-IDF vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=3000)\n",
    "X = vectorizer.fit_transform(df['cleaned_resume'])\n",
    "y = df['Category']\n",
    "\n",
    "# STEP 5: Train-test split with stratification\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# STEP 6: Train Logistic Regression classifier\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# STEP 7: Evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# STEP 8 (Optional): Show a few predictions\n",
    "for i in range(10):\n",
    "    print(f\"Prediction: {y_pred[i]} | Actual: {y_test.iloc[i]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
